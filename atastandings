#!/usr/bin/env python3

"""Search the current ATA World, District and State/Province standings and print the results."""

# SPDX-License-Identifier: MIT
# pylint: disable=too-many-lines

import argparse
import bz2
import glob
import gzip
import html
import io
import json
import os
import random
import re
import sys
import time

import httpx
import yaml

EPILOG = "-W and -S can be used together, or separately. If neither -W nor -S are set, the default is -W."
ATABASE = "https://atamartialarts.com/events/tournament-standings/"
WORLD_SUFFIX = "worlds-standings"
WORLDBASE = f"{ATABASE}{WORLD_SUFFIX}/"
STATE_SUFFIX = "state-standings"
STATEBASE = f"{ATABASE}{STATE_SUFFIX}/"
ZIP_SUFFIXES = [".bz2", ".gz", ""]
CACHE_URL_PREFIX = "atastandings."

NAME_SUFFIXES = ["jr.", "sr.", "i", "ii", "iii", "iv"]
NAME_PREFIXES = ["van", "san", "de", "da", "los", "st.", "saint"]

STANDINGS_DATE = {}
STANDINGS_WORLDS = "worlds"
STANDINGS_STATES = "states"

RANDOM_WORDS = []
USED_WORDS = []
RANDOM_NAME_MAP = {}

OMIT_CHOICES = ["location", "place", "points", "region", "division", "code"]
# add to minimized() when adding to this list
MINIMIZE_CHOICES = ["division"]

CA_PROVINCES = ["AB", "BC", "MB", "NB", "NL", "NS", "NT", "NU", "ON", "PE", "QC", "SK", "YT"]

# fmt: off
US_STATES = [
    "AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL", "GA", "HI", "IA", "ID", "IL", "IN", "KA",
    "KY", "LA", "MA", "MD", "ME", "MI", "MN", "MO", "MS", "NC", "ND", "NH", "NJ", "NM", "NV", "NY", "OH",
    "OK", "OR", "PA", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VT", "WA", "WI", "WV", "WY",
]
# fmt: on

DISTRICTS = {
    "Mid-America": ["wi", "mi", "il", "in", "oh", "ky"],
    "Midwest": ["ne", "ka", "mo"],
    "North": ["nd", "mn", "sd", "ia"],
    "Northeast": ["va", "wv", "md", "pa", "de", "nj", "ny", "ct", "ri", "ma", "vt", "nh", "me", "dc"],
    "Northwest": ["id", "or", "wa", "bc", "ab", "sk", "mb"],
    "Southeast": ["tn", "nc", "sc", "ga", "fl", "al", "ms"],
    "South": ["tx", "la", "ar", "ok"],
    "Southwest": ["az", "nv", "ca"],
    "Rockies": ["nm", "co", "ut", "wy"],
}

COMPETITIONS = {
    "forms": "forms",
    "weapons": "weapons",
    "combat-weapons": "combat weapons",
    "sparring": "sparring",
    "creative-forms": "creative forms",
    "creative-weapons": "creative weapons",
    "x-treme-forms": "x-treme forms",
    "x-treme-weapons": "x-treme weapons",
}
COMPETITIONS_VALUES = COMPETITIONS.values()

# These are options that will not show up in the
# --help output. They are mostly used for maintenance
# of the README.
SUPPRESSED_ARGUMENTS = [
    ("-N", "--randomize-names", True),
    ("-G", "--generate-readme", True),
    ("-2", "--readme-explanation", True),
    ("-M", "--maximum-lines", True),
    ("-X", "--print-readme-heading", False),
    ("-Y", "--print-readme-trailer", False),
    ("-o", "--output", True),
    ("-9", "--internal-checks", False),
]


def get_next_random_word():
    """
    Return the next random word from RANDOM_WORDS.
    Push the word onto USED_WORDS.
    If none are left in RANDOM_WORDS, reassign RANDOM_WORDS and reshuffle.
    """
    # pylint: disable=global-statement
    global RANDOM_WORDS, USED_WORDS
    if not RANDOM_WORDS:
        RANDOM_WORDS = USED_WORDS
        USED_WORDS = []
        random.shuffle(RANDOM_WORDS)
    wd = RANDOM_WORDS.pop(0)
    USED_WORDS.append(wd)
    return wd


def get_random_word(nm):
    """
    Given a name, return a random name to use in its place.
    Do this by grabbing two random words at a time from the front of the list.
    """
    while True:
        repl_name = get_next_random_word().capitalize() + get_next_random_word()
        if repl_name not in RANDOM_NAME_MAP:
            RANDOM_NAME_MAP[nm] = repl_name
            return repl_name


def get_random_name(args, nm):
    """
    Given a name, and randomizing is on, return a random name to use in its place.
    """
    if not args.randomize_names:
        return nm

    if not RANDOM_WORDS and not USED_WORDS:
        with open(args.randomize_names) as fp:
            for l in fp:
                RANDOM_WORDS.append(l.strip().lower())
        random.shuffle(RANDOM_WORDS)
        for nms in NAME_SUFFIXES:
            RANDOM_NAME_MAP[nms] = nms
        for nmp in NAME_PREFIXES:
            RANDOM_NAME_MAP[nmp] = nmp

    newname = []
    for l in nm.lower().split():
        newname.append(get_random_word(l))
    return " ".join(newname)


def get_cache_dir():
    """Determine the directory where to store a cache of the web files"""
    for name in ["TEMP", "TMP", "TMPDIR", "TEMPDIR"]:
        dirname = os.environ.get(name)
        if dirname and os.path.isdir(dirname):
            return dirname
    return "/tmp"


def strip_html(l):
    """strip out all html <tags>"""
    l = re.sub("<[^>]*>", "", l)
    l = re.sub(r"\s+", " ", l)
    return l


def cache_stat(cachename):
    """Search the cachename for .gz, .bz2, "" versions. Return cachename with suffix plus stat info."""
    for suffix in ZIP_SUFFIXES:
        try:
            st = os.stat(cachename + suffix)
            # print(f"found {cachename + suffix}")
            return (cachename + suffix, st)
        except FileNotFoundError:
            pass
    return (cachename, None)


def open_cache_read(cachename, mode="rt"):
    """Open the file, with the appropriate gzip/bzip2/"" open() function."""
    if cachename.endswith(".gz"):
        return gzip.open(cachename, mode)
    if cachename.endswith(".bz2"):
        return bz2.open(cachename, mode)
    return open(cachename, mode)


def open_cache_write(args, cachename, mode="wt"):
    """Open the file, with the appropriate gzip/bzip2/"" open() function."""
    if args.bzip2_cache:
        return bz2.open(cachename, mode)
    if args.gzip_cache:
        return gzip.open(cachename, mode)
    return open(cachename, mode)


def decode_url(cache_name):
    """
    From a cache_name, atastandings.<<encoded-url>>,
    recreate the original URL.
    Account for gz/bz2 suffixes
    """
    if cache_name.startswith(CACHE_URL_PREFIX):
        cache_name = cache_name[len(CACHE_URL_PREFIX) :]
    for suffix in ZIP_SUFFIXES:
        if suffix and cache_name.endswith(suffix):
            cache_name = cache_name[: -len(suffix)]
            break

    ret = []
    i = 0
    while i < len(cache_name):
        if cache_name[i] == "_":
            if cache_name[i + 1] == "_":
                ret.append("_")
                i += 2
            else:
                c = cache_name[i + 1 : i + 3]
                # print(f"c={c}")
                ic = int(c, 16)
                # print(f"ic={ic}, chr(ic)={chr(ic)}")
                ret.append(chr(ic))
                i += 3
        else:
            ret.append(cache_name[i])
            i += 1
    return ATABASE + "".join(ret)


def get_cache_name(url):
    """
    From a url, generate an encoded version.
    Trim off the ATABASE.
    Use encoding similar to url %-encoding on all special characters,
    but with '_' instead of '%'.
    """
    sig_url = url[len(ATABASE) :]
    ret = []

    for c in sig_url:
        if c == "_":
            ret.append("__")
        elif c not in "abcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ":
            ret.append("_" + hex(ord(c)).replace("0x", ""))
        else:
            ret.append(c)

    return "".join(ret)


def extra_verbose(args, level, msg):
    """
    If args.verbose, print the message.
    """
    if args.verbose >= level:
        print(msg, file=sys.stderr, flush=True)


def verbose(args, msg):
    """
    If args.verbose, print the message.
    """
    if args.verbose:
        print(msg, file=sys.stderr, flush=True)


def dots(args, msg):
    """
    If args.dots, print the propre dot.
    """
    if args.dots:
        print(msg, end="", file=sys.stderr, flush=True)


def expire_old_cache_file(args, cachename):
    """
    Go through the cache file variations and remove them all.
    """
    found = False
    for sfx in ZIP_SUFFIXES:
        try:
            os.unlink(cachename + sfx)
            found = True
        except FileNotFoundError:
            pass

    if found:
        verbose(args, f"{cachename} is too old -- removed")


def get_cache(args, cachename_base, url_type):
    """
    Retrieve a URL from the cache.
    Return the body as an array of lines.

    The cache is designed so that most web pages are visited exactly once.
    This speeds up running the program multiple times in a row.
    There are options to ignore, disable and clean the cache.

    With use-web-standings-dates caching, the first state/world file is retrieved from the web and
    examined for the "Standings updated on mm/dd/yyyy" date.
    Subsequent cached files are checked for their dates and only re-retrieved if the dates are different.

    With time-based caching, cache files older than 24 hours are automatically ignored.
    """
    try:
        verbose(args, f"looking for {cachename_base}")

        (cachename, st) = cache_stat(cachename_base)
        if not args.offline and args.use_time_based_cache:
            if st is not None:
                verbose(
                    args,
                    "args.use_time_based_cache and st is not None",
                )

                if time.time() - st.st_mtime > 24 * 60 * 60:  # ignore files older than 24 hours
                    verbose(args, "\texpiring cache")
                    expire_old_cache_file(args, cachename)
                    return (None, True)

        dots(args, ".")

        with open_cache_read(cachename) as fp:
            text = fp.read()

        cache_standings_date = get_standings_date(text)
        if not args.use_web_standings_dates or args.offline:
            verbose(args, "not use_web_standings_dates or offline")
            if url_type not in STANDINGS_DATE:
                STANDINGS_DATE[url_type] = cache_standings_date
            return (text.splitlines(), False)

        if url_type in STANDINGS_DATE:
            verbose(args, f"url_type({url_type}) in {STANDINGS_DATE}")
            verbose(args, f"cache_standings_date={cache_standings_date}")
            if STANDINGS_DATE[url_type] == cache_standings_date:
                verbose(args, "dates are ==")
                dots(args, ",")
                return (text.splitlines(), False)

        else:
            verbose(args, f"url_type({url_type}) NOT in {STANDINGS_DATE}")
            verbose(args, f"cache_standings_date={cache_standings_date}")
            if time.time() - st.st_mtime < 5 * 60:
                # recent enough we can use the file
                verbose(args, f"url_type({url_type}) is recent")
                verbose(args, f"cache_standings_date={cache_standings_date}")
                dots(args, f"[{cache_standings_date}]")
                STANDINGS_DATE[url_type] = cache_standings_date
                return (text.splitlines(), False)

    except FileNotFoundError:
        # no cache
        pass

    return (None, True)


def get_url(args, url, url_type):
    """
    Retrieve a URL, either from the cache or from web.
    Exit with an error message if there is an error retrieving it.
    Return the body as an array of lines.
    """
    urlname = get_cache_name(url)
    cachename_base = f"{args.cache_directory}/{CACHE_URL_PREFIX}{urlname}"

    if not args.ignore_existing_cache:
        (textlines, cret) = get_cache(args, cachename_base, url_type)
        if textlines:
            return (textlines, cret)

    if args.offline:
        sys.exit(f"Cannot find cache for {url}")

    verbose(args, "getting url")

    dots(args, ":")

    r = None
    errmsg = None
    verbose(args, f"getting url={url}")
    for i in range(args.connection_count):
        errmsg = None
        try:
            r = httpx.get(url)
        except httpx.ReadTimeout:
            errmsg = f"Timeout for {url}"
        except httpx.ConnectError:
            errmsg = f"ConnectError for {url}"
        except httpx.ReadError:
            errmsg = f"ReadError for {url}"
        except httpx.RequestError as e:
            errmsg = f"HTTP Exception for {e.request.url} - {e}"
        except httpx.HTTPError as e:
            errmsg = f"HTTP Exception for {e.request.url} - {e}"
        except Exception as e:
            errmsg = f"Other conn error for {url}: {type(e)}: {e}"

        if r:
            break

        print(f"#{i+1}: {errmsg}", file=sys.stderr, flush=True)
        errmsg = None
        time.sleep(args.retry_interval)

    if r is None:
        if args.connection_count > 1:
            sys.exit("Connection count reached")
        else:
            sys.exit(1)

    if r.status_code >= 300:
        sys.exit(f"Accessing {url} returned the status code {r.status_code}")

    if args.request_interval:
        time.sleep(args.request_interval)
    web_standings_date = get_standings_date(r.text)
    if url_type not in STANDINGS_DATE:
        STANDINGS_DATE[url_type] = web_standings_date

    extra_verbose(args, 2, f"page={r.text}")
    if not args.do_not_write_cache:
        suffix = ".bz2" if args.bzip2_cache else ".gz" if args.gzip_cache else ""
        verbose(args, f"writing to {cachename_base}{suffix}")
        with open_cache_write(args, f"{cachename_base}{suffix}.tmp", "wt") as fp:
            fp.write(r.text)
        os.rename(f"{cachename_base}{suffix}.tmp", f"{cachename_base}{suffix}")
    text = r.text

    return (text.splitlines(), True)


def clean_cache(args):
    """Clear out all files in the cache directory named "atastandings." followed by anything."""
    for fname in glob.glob(f"{args.cache_directory}/atastandings.*"):
        verbose(args, f"Cleaning {fname}")
        os.unlink(fname)


def trim_border(lines, border):
    """
    Trim all lines up through the first line that includes the string border.
    Then trim all lines after border occurs again.
    Also trim any lines after "Listed Tournaments"
    """
    nl = []
    saving = False
    for l in lines:
        if border in l:
            if saving:
                break
        elif "Listed Tournaments" in l:
            break
        if saving:
            nl.append(l)
        if border in l:
            saving = True
    return nl


def join_li_td_tr(lines):
    """Join any lines that end with </li>, </td> and </th> with the subsequent line"""
    for i in range(len(lines) - 1):
        l = lines[i].strip().replace(" ", "")
        if l.endswith("</li>") or l.endswith("</td>") or l.endswith("</th>"):
            lines[i + 1] = lines[i] + lines[i + 1]
            lines[i] = ""
    return lines


def fgrep(s, lines):
    """Search for lines that have the given string and return that array"""
    newlines = []
    for l in lines:
        if s in l:
            newlines.append(l)
    return newlines


def get_code(l):
    """Extract code=ABC from a line"""
    l = re.sub("^.*code=", "code=", l)
    l = re.sub('".*$', "", l)
    return l


def fix_html(s):
    """Look in a string and replace instances of &xyz; with the equivalent values"""
    return html.unescape(s)


def get_codes(args, url, url_type):
    """Retrieve a URL. Retrieve the list of codes as an array of [division-code, division-name]"""
    (lines, _) = get_url(args, url, url_type)
    lines = fgrep("code=", join_li_td_tr(lines))
    nl = []
    for l in lines:
        nl.append([get_code(l), strip_html(l).replace("VIEW", "")])
    return nl


def print_lines(lines):
    """print the lines of an array"""
    for l in lines:
        print(l)


def get_info(args, code, region, url, border, url_type):  # pylint: disable=too-many-positional-arguments
    """Get the standings from this url"""
    (lines, _) = get_url(args, url, url_type)
    lines = trim_border(lines, border)
    dispcode = code[0].split("=")[1]
    for i, val in enumerate(lines):
        if "text-primary" in val:
            lines[i] = f"DIVISION {dispcode} {val}"
        lines[i] = re.sub(" +", " ", lines[i])
        lines[i] = re.sub('style="[^"]*"', "", lines[i])
        lines[i] = re.sub('class="[^"]*"', "", lines[i])

    lines = join_li_td_tr(lines)

    nl = []
    for l in lines:
        l = l.replace("</td>", "").replace("</th>", "").replace("</li>", "")
        l = re.sub("<t[rd][^>]*>", " | ", l)
        l = re.sub(r"^\s+[|]\s+", " ", l)
        l = re.sub("<[^>]*>", "", l)  # eliminates ALL html tags
        l = (
            l.replace("The points below", "")
            .replace("Back to Map", "")
            .replace("reflect the following tournaments", "")
        )
        l = re.sub(r"\s+", " ", l)
        if l in ("", " "):
            continue
        nl.append(l)

    # Convert the division info to a structure
    info = []
    curinfo = {}
    for l in nl:
        if l.startswith("DIVISION"):
            div_parts = l.strip().split()
            curinfo = {
                "code": div_parts[1],
                "division": " ".join(div_parts[2:]),
                "region": region,
                "other_header": [],
                "places": [],
            }
            info.append(curinfo)
        elif re.match(r"\s*[a-zA-Z]", l):
            if curinfo:
                curinfo["other_header"].append(l)
        elif re.match(r"\s*[0-9]+ .*" + args.search, l, flags=re.IGNORECASE):
            if curinfo:
                place_info = l.split("|")
                curinfo["places"].append(
                    {
                        "place": int(place_info[0]),
                        "name": fix_html(get_random_name(args, place_info[1].strip())),
                        "points": int(place_info[2].strip()),
                        "location": fix_html(place_info[3].strip()),
                    }
                )
    return info


def renumber_places(places):
    """
    Given an array of places, sorted by score, change the "place" value to match the order.
    """
    last_place = 0
    last_score = 0
    index = 0
    for p in places:
        index += 1
        if p["points"] != last_score:
            last_place = index
        p["place"] = last_place
        last_score = p["points"]


def trim_info(args, info, place_only=False):
    """
    Apply the --search and --maximum-place criteria against the info array.
    """
    for i in info:
        new_places = []
        if not place_only:
            if args.competition:
                ldivision = i["division"].lower()
                found_competition = False
                for competition in args.competition:
                    if ldivision.startswith(COMPETITIONS[competition]):
                        found_competition = True
                        break
                if not found_competition:
                    # get rid of this one right now
                    i["places"] = []

            if args.keep_division_if:
                keep_division = False
                for j in i["places"]:
                    for k in args.keep_division_if:
                        if k.lower() in j["name"].lower() or k.lower() in j["location"].lower():
                            keep_division = True
                            break
                if not keep_division:
                    # get rid of this one right now
                    i["places"] = []

        for j in i["places"]:
            keep = True
            if j["place"] > args.maximum_place:
                keep = False
            if args.search and not place_only:
                if args.search.lower() not in j["name"].lower() and args.search.lower() not in j["location"].lower():
                    keep = False

            if keep:
                new_places.append(j)
        i["places"] = new_places

    new_info = []
    for i in info:
        if i["places"]:
            new_info.append(i)
    return new_info


def info_by_name(info):
    """given a structure'd set of standings, print it by division"""
    # {
    #    sortable_name => { "name": str, "location": str,
    #              "divisions": [
    #                  { "region": str, "division": str, "code": str, "place": int, "points": int }, ...
    #              ]}
    name_info = {}
    for i in info:
        for j in i["places"]:
            sname = sortable_name(j["name"])
            if sname not in name_info:
                name_info[sname] = {"name": j["name"], "divisions": [], "location": j["location"]}
            name_info[sname]["divisions"].append(
                {
                    "region": i["region"],
                    "division": i["division"],
                    "code": i["code"],
                    "place": j["place"],
                    "points": j["points"],
                }
            )

    return name_info


def minimized(args, nm, prefix, s):
    """
    Check if nm is in the args.minimized list.
    If not, return the string s.
    If so, return a mimized version of the string.
    """
    if args.minimize and nm in args.minimize:
        # if nm == "division", etc. Add to this when
        for words in COMPETITIONS_VALUES:
            if str(s).upper().startswith(words.upper()):
                return prefix + words.title()
    return prefix + str(s)


def omitted(args, nm, prefix, s):
    """
    Check if nm is in the args.omit list.
    If not, return the string s.
    If so, return an empty string.
    """
    return minimized(args, nm, prefix, s) if not args.omit or nm not in args.omit else ""  # if nm in args.omit else s


def print_omitted(args, nm, prefix, s):
    """
    Check if nm is in the args.omit list.
    If not, print the string s without a line ending.
    """
    print(omitted(args, nm, prefix, s), end="")


def sortable_name(nm):
    """
    Return a name as LAST, FIRST.
    Suffixes "jr.", "sr.", "i", "ii", "iii" and "iv" are considered part of the last name
    Prefixes "van", "san", "de", "da", "los" "st.", "saint" are considered part of the last name
    """
    nm_parts = nm.lower().split()
    end = len(nm_parts)
    if nm_parts[end - 1] in NAME_SUFFIXES:
        end -= 1
    while end > 2 and nm_parts[end - 2] in NAME_PREFIXES:
        end -= 1
    return " ".join(nm_parts[end - 1 :]) + ", " + " ".join(nm_parts[0 : end - 1])


def print_info_by_name(args, info):
    """given a structure'd set of standings, print it by name"""
    name_info = info_by_name(info)
    for name in sorted(name_info.keys()):
        val = name_info[name]
        print_omitted(args, "name", "", val["name"])
        print_omitted(args, "location", " | ", val["location"])
        if args.by_person_with_divisions:
            for div in val["divisions"]:
                print(" |", end="")
                print_omitted(args, "region", " ", div["region"])
                print_omitted(args, "place", " ", div["place"])
                print_omitted(args, "code", " ", div["code"])
                print_omitted(args, "division", " ", div["division"])
                print_omitted(args, "points", " ", div["points"])
        print("")


def print_info_by_division(args, info):
    """Given a structure'd set of standings, print it by division"""
    verbose(args, info)
    for i in info:
        print("DIVISION", end="")
        print_omitted(args, "region", " ", i["region"])
        print_omitted(args, "code", " ", i["code"])
        print_omitted(args, "division", " ", i["division"])
        print("")

        print_omitted(args, "place", " ", "Place")
        print_omitted(args, "name", " ", "Name")
        print_omitted(args, "points", " ", "Pts")
        print_omitted(args, "location", " ", "Location")
        print("")

        for j in i["places"]:
            print_omitted(args, "place", " ", j["place"])
            print_omitted(args, "name", " ", j["name"])
            print_omitted(args, "points", " ", j["points"])
            print_omitted(args, "location", " ", j["location"])
            print("")


def print_info(args, data):
    """Given a structure'd set of standings, print it appropriately"""
    dots(args, "\n")
    if args.output_json:
        json.dump(data, sys.stdout, indent=4)
        print()

    if args.print:
        print(data["title"])
        if args.by_person or args.by_person_with_divisions:
            print_info_by_name(args, data["all_info"])
        else:
            print_info_by_division(args, data["all_info"])


def get_country(state):
    """Return the appropriate country for a given state"""
    # https://atamartialarts.com/Scripts/state-standing.bundle.js
    # Set the country code appropriately based on the state.
    # Experimentally, it looks like "country=$COUNTRY" is NOT required,
    # but we'll pass it in anyway.
    if state in CA_PROVINCES:
        country = "CA"
    else:
        country = "US"
    return country


def upper_case(lst):
    """Convert all elements in the array to uppercase"""
    if lst:
        for i, l in enumerate(lst):
            lst[i] = l.upper()


def print_worlds(args):
    """Print the worlds standings"""
    if args.division_code:
        codes = [[f"code={code}", ""] for code in args.division_code]
    else:
        codes = get_codes(args, WORLDBASE, STANDINGS_WORLDS)

    if args.list_division_codes:
        print("WORLD STANDINGS DIVISIONS")
        for code in codes:
            print(f"{code[0].split('=')[1]}: {code[1]}")

    else:
        title = "WORLD STANDINGS"
        if args.search:
            title += f", searching for '{args.search}'"
        title += f", maximum place of {args.maximum_place}"
        data = {"title": title, "date": None, "worlds": "worlds", "all_info": []}

        for code in codes:
            info = get_info(args, code, "WORLDS", f"{WORLDBASE}?{code[0]}", "INFO", STANDINGS_WORLDS)
            data["all_info"] += info

        data["date"] = STANDINGS_DATE[STANDINGS_WORLDS]
        data["all_info"] = trim_info(args, data["all_info"])
        print_info(args, data)


def print_districts(args, need_nl):
    """Print the district standings"""

    for district in args.district:
        if need_nl or district != args.district[0]:
            if args.list_division_codes:
                print("")

        if args.division_code:
            codes = [[f"code={code}", ""] for code in args.division_code]

        if args.list_division_codes:
            if not args.division_code:
                # The codes are the set of the codes from all of the states.
                # We don't use the world's set of codes because we also need
                # any color belt divisions.
                codes = []
                codeset = set()
                for state in DISTRICTS[district]:
                    country = get_country(state)
                    ncodes = get_codes(args, f"{STATEBASE}?country={country}&state={state}", STANDINGS_STATES)
                    for code in ncodes:
                        if code[0] not in codeset:
                            codes.append(code)
                            codeset.add(code[0])

            print(f"DISTRICT STANDINGS DIVISIONS FOR {district}")
            for code in codes:
                print(f"{code[0].split('=')[1]}: {code[1]}")

        else:
            title = f"DISTRICT STANDINGS FOR {district}"
            if args.search:
                title += f", searching for '{args.search}'"
            title += f", maximum place of {args.maximum_place}"
            data = {"title": title, "date": None, "district": district, "all_info": []}

            for state in DISTRICTS[district]:
                country = get_country(state)
                if not args.division_code:
                    country = get_country(state)
                    codes = get_codes(args, f"{STATEBASE}?country={country}&state={state}", STANDINGS_STATES)

                for code in codes:
                    info = get_info(
                        args,
                        code,
                        district,
                        f"{STATEBASE}?country={country}&state={state}&{code[0]}",
                        "CONTENT",
                        STANDINGS_STATES,
                    )
                    info = trim_info(args, info, place_only=True)
                    for i in info:
                        # if the corresponding i[division] is in all_info.division,
                        #     append i[places] to all_info[places]
                        # otherwise
                        #     add this entire i to all_info
                        found = False
                        for ai in data["all_info"]:
                            if i["division"] == ai["division"]:
                                found = True
                                ai["places"] += i["places"]
                                break

                        if not found:
                            data["all_info"].append(i)

            ################
            # After collecting all of the information in the states of the district
            ################

            # Sort and renumber the places arrays
            for ai in data["all_info"]:
                ai["places"] = sorted(ai["places"], key=lambda k: (-k["points"], sortable_name(k["name"])))
                renumber_places(ai["places"])

            data["date"] = STANDINGS_DATE[STANDINGS_STATES]
            data["all_info"] = trim_info(args, data["all_info"])
            print_info(args, data)


def print_states(args, need_nl):
    """Print the state standings"""
    for state in args.state:
        if need_nl or state != args.state[0]:
            if args.list_division_codes:
                print("")

        country = get_country(state)

        if args.division_code:
            codes = [[f"code={code}", ""] for code in args.division_code]
        else:
            codes = get_codes(args, f"{STATEBASE}?country={country}&state={state}", STANDINGS_STATES)

        if args.list_division_codes:
            print(f"STATE STANDINGS DIVISIONS FOR {state}")
            for code in codes:
                print(f"{code[0].split('=')[1]}: {code[1]}")

        else:
            title = f"STATE STANDINGS FOR {state}"
            if args.search:
                title += f", searching for '{args.search}'"
            title += f", maximum place of {args.maximum_place}"
            data = {"title": title, "date": None, "state": state, "all_info": []}

            for code in codes:
                info = get_info(
                    args,
                    code,
                    state,
                    f"{STATEBASE}?country={country}&state={state}&{code[0]}",
                    "CONTENT",
                    STANDINGS_STATES,
                )
                data["all_info"] += info

            data["date"] = STANDINGS_DATE[STANDINGS_STATES]
            data["all_info"] = trim_info(args, data["all_info"])
            print_info(args, data)


def print_top(args):
    """
    Print the top args.maximum_place positions in the given divisions.
    """
    states = []
    if args.district:
        for district in args.district:
            for state in DISTRICTS[district]:
                states.append(state)
    if args.state:
        for state in args.state:
            states.append(state)

    title = f"TOP {args.maximum_place} STANDINGS"
    if args.search:
        title += f", searching for '{args.search}'"
    if args.district:
        title += ", in districts "
        title += ", ".join(args.district)
        if args.state:
            title += "; and in states "
    if args.state:
        if not args.district:
            title += "; in states "
        title += ", ".join(args.state)

    data = {"title": title, "date": None, "top": args.maximum_place, "all_info": []}

    for state in states:
        country = get_country(state)
        if not args.division_code:
            country = get_country(state)
            codes = get_codes(args, f"{STATEBASE}?country={country}&state={state}", STANDINGS_STATES)
        else:
            codes = args.division_code

        for code in codes:
            info = get_info(
                args,
                code,
                "combined",
                f"{STATEBASE}?country={country}&state={state}&{code[0]}",
                "CONTENT",
                STANDINGS_STATES,
            )
            info = trim_info(args, info, place_only=True)
            for i in info:
                # if the corresponding i[division] is in all_info.division,
                #     append i[places] to all_info[places]
                # otherwise
                #     add this entire i to all_info
                found = False
                for ai in data["all_info"]:
                    if i["division"] == ai["division"]:
                        found = True
                        ai["places"] += i["places"]
                        break

                if not found:
                    data["all_info"].append(i)

    ################
    # After collecting all of the information in the states of the specified districts and states
    ################

    # Sort and renumber the places arrays
    for ai in data["all_info"]:
        ai["places"] = sorted(ai["places"], key=lambda k: (-k["points"], sortable_name(k["name"])))
        renumber_places(ai["places"])

    data["date"] = STANDINGS_DATE[STANDINGS_STATES]
    data["all_info"] = trim_info(args, data["all_info"])
    print_info(args, data)


def check_option(arglist, opts, choices):
    """check the values in the arglist against a list of choices"""
    if arglist:
        for arg in arglist:
            if arg not in choices:
                sys.exit(
                    f"{sys.argv[0]}: error: argument {opts}: invalid choice: '{arg}' (choose from " f"{list(choices)})"
                )


def printable_list(lst, sep=", ", sep2=" or "):
    """
    From an array, create a printable version of it.
    For example, ['a', 'b'] would return
    'a' or 'b'
    ['a', 'b', 'c'] would return
    'a', 'b' or 'c'
    ['a'] would return
    'a'
    """
    l = len(lst)
    lst = sorted(lst)
    if l == 1:
        return repr(lst[0])
    if l == 2:
        return repr(lst[0]) + sep2 + repr(lst[1])
    ret = sep.join([repr(a) for a in lst[:-1]])
    ret += sep2
    ret += repr(lst[-1])
    return ret


def get_no_options(args):
    """
    From the options, return a list of those that begin with the string "--no-".
    """
    ret = []
    for arg in args:
        for opt in arg.option_strings:
            if opt.startswith("--no-"):
                ret.append(opt)
    return ret


def print_readme_heading(args_actions, print_example_preamble=True):
    """Print the opening of the readme file."""
    # pylint: disable=line-too-long
    hdr = (
        """
    |# ATA (American Taekwondo Association) World and State Standings Printer
    |
    |The American Taekwondo Association's tournament series has its results online.
    |However, the user interface is oriented towards looking at a division at a time
    |and has no provisions for searching based on a person's name or school.
    |
    |# atastandings Options
    |
    |All `atastandings` options are specified using two hyphens (`--`) and the option name,
    |possibly followed by an argument such as a search string or a state/province abbreviation.
    |There are also short versions of many of the options that are a single hyphen and a single lettter.
    |
    |## Worlds, District, State and Top Standings
    |The default for `atastandings` is to search the world standings.
    |You can instead ask it to search one or more state or district standings.
    |
    |* `--worlds`, `-W` -- search the world standings.
    |* `--district name`, `-d name` -- search the given district, one of
    |    """
        + printable_list(list(DISTRICTS.keys()), ",\n    ", " or\n    ")
        + """.
    |
    |This may be specified multiple times. You may also specify a list, as in `--district 'Midwest,South'`.
    |Or you may specify `--all-districts`.
    |
    |* `--state ABBREV`, `-S ABBREV`, `--province ABBREV` -- search the given state or province,
    |using the two character state or province postoffice code. (`--state` and `--province` are
    |treated identically in the code.)
    |
    |This may be specified multiple times. You may also specify a list, as in `--state 'CA,AK'`.
    |Or you may specify `--all-states`, `--all-us` or `--all-canada`. (Mutually exclusive.)
    |
    |For example, both `atastandings` and  `atastandings --worlds` will search the world standings.
    |`atastandings --district northeast` will search the Northeast district.
    |`atastandings --state pa --state ca` will search the state standings for Pennsylvania and California.
    |`atastandings --worlds --state ca` will search both the world stands and the state standings for California.
    |
    | `--top` -- This option can be combined with `--state`/`-S` and `--district`/`-d` to
    |print the top people across the specified states/provinces and districts in order.
    |(The `--maximum-place`/`-p` option can be used to change the number of places. See below.)
    |
    |For example, `atastandings --top --maximum-place 20 --district Northeast` will
    |print the top 20 people in each division across states in the Northeast district.
    |
    |## Division Control
    |
    |The default for `atastandings` is to print information for *all* divisions.
    |Alternatively, you can restrict your output to specific division codes.
    |For example, the division code for **1st Degree Black Belt Age 9 - 10** is *B01B*.
    |
    |To find out what the division codes are, you can get a list:
    |
    |* `--list-division-codes`, `-l` -- list all of the division codes.
    |This  can be combined with `--district name`, or `--state STATE-ABBREV` to get the division codes specific to a state/province.
    |
    |* `--division-code code`, `-c code` -- Restrict the output to the specified diision code.
    |This may be specified multiple times.
    |* `--competition competition` -- Only print this competition, one of
    |    """
        + printable_list(list(COMPETITIONS.keys()), ",\n    ", " or\n    ")
        + """.
    |May be specified multiple times, or as a list such as `--competiton 'forms,weapons'`.
    |
    |(Not all divisions have competitors in each state or province.
    |Also, color belt divisions will not show in the world standings list.)
    |
    |## Searching
    |
    |There are two types of searching available.
    |* `--search string`, `-s string` -- Only print entries that have this string in either the person's name OR the school location. (Case is ignored.)
    |* `--keep-division-if string`, `-k string` -- Only print a division if the string is found in any of the people's names or school locations in the division.
    |
    |## Place Standings
    |
    |The default for `atastandings` is to print all current place standings in each division.
    |The place standings for each state on the web site show the top 10 people, but you might only
    |be interested in who the first place leaders are.
    |
    |* `--maximum-place MAXIMUM-PLACE`, `-p MAXIMUM-PLACE` -- limit the output to only those whose place is less than or equal to the specified maximum place.
    |
    |For example, `--maximum-place 1` would print only the first place leaders,
    |and `--maximum-place 4` will print only the top four contenders.
    |
    |## By Person Printing (Champion Status)
    |Normally, `atastandings` prints the results arranged by division.
    |You might prefer the printout to be arranged by an individual's name instead, with or without the division information.
    |The names are printed in order, sorted by last name.
    |(Suffixes like "Jr." and prefixes like "van" are taken into consideration in the sorting process.)
    |
    |* `--by-person`, `-b` -- Print the names and location of each individual.
    |* `--by-person-with-divisions`, `-B` -- Print the names and location of each individual, followed by a list of their divisions.
    |
    |## Omitting Information
    |Normally, `atastandings` will print all information, including such things as the location, place and points.
    |You can choose to omit pieces of information.
    |
    |* `--omit item`, `-O item` -- Omit information from the printouts,
    |where `item` is one of """
        + printable_list(OMIT_CHOICES)
        + """.
    |The `region` is either the world "WORLDS" or the state or province name.
    |The code is the division code.
    |This may be specified multiple times, or you may specify a list, as in `--omit 'location,place'`.
    |
    |* `--minimize item`, `-m item` -- Minimize information from the printouts,
    |where `item` is currently only `division`.
    |For `division`, a division such as `Forms Boys Color Belt 9 - 10 Years Old` would be minimized to just `Forms`.
    |        (The division code, which is usually printed as well, can be used to differentiate between divisions.)
    |When there is more than `division` allowed, this may be specified multiple times or as a list.)
    |
    |## Connection Options
    |When making connections there will be an occasional network failure. From the command line, you
    |can easily restart the command. But if being run in the background, a better strategy is to
    |retry the connection. To support this, you can set `--connection-count` to a value such as 10 with
    |a `--retry-interval` value such as `30` (seconds). When the `connection-count` is reached, the
    |program will exit with an error message. (Note: the `connection-count` restarts for each web
    |page requested.
    |
    |To combat too many network failures, it is possible to set a pause after each successful network connection.
    |This can be set with --request-interval, which defaults to 1 second.
    |
    |## Web Cache
    |By default, `atastandings` maintains a cache of the web sites, so that you can have faster response times
    |when you run the program multiple times.
    |Most of the time you can ignore that the cache is being used, but power users might want additional controls.
    |
    |### *Standings Date* Cache
    |The default form of cache verification downloads the first state or world file that is needed, and looks
    }for the 'updated on' value. If the value is the same in each subsequent state/world standings file,
    |that state/world cache file will not be downloaded.
    |(If the first file is less than 5 minutes old, it will not be re-downloaded but used as-is.)
    |This type of cache verification is enabled using `--use-web-standings-dates`/`-w`.
    |
    |### Time-Based Cache
    |With the time-based cache, files older than 24 hours are automatically re-downloaded.
    |
    |### Turning Off Caching
    |The `-T`/`--ignore-cache` can be used if you wish to turn off caching.
    |
    |* `--cache-directory PATH`, `-C PATH` -- This will set the cache directory to the given path.
    |It defaults to an os-specific temp directory.
    |* `--clean-cache` -- Sometimes you might wish to clean up all of the cached files.
    |All cache files are named `atastandings.` followed by a long string of characters representing the web file being referenced.
    |* `--ignore-existing-cache`, `-I` -- Sometimes you might want the existing cache to be ignored, but still created.
    |Doing this will give you slower response times.
    |* `--ignore-cache-times`, `-T` -- Sometimes you want to ignore that the fact that the cache file is older than 24 hours.
    |* `--do-not-write-cache`, `-D` -- Sometimes you might want the cache files to not be written.
    |For example, you can use this option if there are problems on your system with the cache directory.
    |
    |You can use `--update-cache` to check the cached files and update them, without doing any further
    |analysis.
    |
    |By default, the cache files are stored as read from the web. However, the `--gzip-cache` and
    |`--bzip2-cache` options cause the cache files to be compressed. The `gzip` algorithm is slightly
    |faster than the `bzip2` algorithm, but the latter creates slightly smaller files.
    |
    |Another option is `--offline`, which causes the program to ONLY run via the cache and to give
    |an error if a required cache file is not found.
    |
    |        Note: Not using the cache will give you slow response times every time you run the program because of the web lookups.
    |
    |
    |## Getting Help and Miscellaneous Other Options
    |
    |* `--dots`, `-.` -- Dots or colons will be printed for each file that is being retrieved from the
    |web (":"), the time-based cache (".") or the updated-on date (",").
    |
    |Finally, you can ask for help on what options are available:
    |
    |* `--help`, `-h` -- Show a help message listing all of the options and variations.
    |* `--extended-help` -- Show the preamble of the README
    |
    |## Configuration File
    |Some of the options shown above can be specified in a configuration file.
    |This should be a file named .atastandings.ini that lives in the same
    |directory/folder as the atastandings program itself or the user's
    |HOME/HOMEPATH directory/folder.
    |It consists of lines that have the configuration option, a colon (`:`) and a value.
    |Use `#` to start a comment.
    |Use `true` and `false` for boolean options. The options that can be specified in
    |the configuration file and their default values are:
    |
    |    by-person: false
    |    by-person-with-divisions: false
    |    list-division-codes: false
    |    omit: ""
    |    minimize: ""
    |    cache-directory: ""
    |    dots: false
    |    gzip-cache: false
    |    bzip2-cache: false
    |    offline: false
    |    ignore-cache-times: false
    |    use-web-standings-dates: false
    |    connection-count: 1
    |    retry-interval: 30
    |
    |Some options (such as `--dots`) have `--no-` versions that allow the option to be turned on
    |in the configuration file, and then be turned off from the command line. The options that currently
    |allow `--no-` options to be specified are:
    |"""
        + printable_list(get_no_options(args_actions))
        + """.
    |
    |## Configuration environment variable
    |The options in a configuration file are also settable in an ATASTANDINGS environment variable.
    |Use the same format as the configuration file, but separate the variables with a semi-colon ("`;`"),
    |as in `ATASTANDINGS='dots: true; list-division-codes: true'`.
    |
    |"""
    ).replace("    |", "")[1:]
    print(hdr)

    if print_example_preamble:
        print(
            """
    |# Sample Use Examples
    |
    |The following examples show some of the ways that the various options can be combined together.
    |All sample output uses fictitious names, and only shows the first 10 lines of the output.
    |
    |""".replace(
                "    |", ""
            )[
                1:
            ]
        )
    # pylint: enable=line-too-long
    sys.exit()


def print_readme_trailer():
    """Print the trailer of the readme file."""
    # pylint: disable=line-too-long
    print(
        """
    |# Installation
    |This program was written using python3, so you will need a python3 environment to run it.
    |You will also need the python `httpx` library.
    |(In my opinion, if you have a Windows system, the easiest way to install a full python3
    |environment is to install the MicroSoft WSL2 infrastructure, which will include python3
    |and many other tools.)
    |
    |If you do not have the `httpx` library, you will need to run a command such as this to load it:
    |``` shell
    |pip3 install httpx
    |```
    |
    |Depending on your installation, you may also need to install
    |the `pyyaml` library.
    |
    |Put the atastandings script somewhere in your path, make sure it is executable
    |(in Linux and WSL, `chmod a+x atastandings`) and run it with the options you desire.
    |Or you can invoke the script directly with python3, as in `python3 atastandings` followed
    |by the options you desire.
    |You might need to execute it as `./atastandings` followed by the options you desire.
    |""".replace(
            "    |", ""
        )[
            1:
        ]
    )
    # pylint: enable=line-too-long
    sys.exit()


def start_readme(args):
    """
    Print the preamble of a readme segment, and set up capturing the output.
    If also printing a maximum # of lines, redirect stdout and
    return the old sys.stdout
    """
    print(f"## `{args.generate_readme}`")
    print(f"`{os.path.basename(sys.argv[0])}", end="")
    sa1 = [item for sa in SUPPRESSED_ARGUMENTS for item in sa]

    skip = False
    for arg in sys.argv[1:]:
        if skip:
            skip = False
        elif arg in sa1:
            skip = True
        elif " " in arg:
            print(f' "{arg}"', end="")
        else:
            print(f" {arg}", end="")

    print("`")
    if args.readme_explanation:
        print("")
        print(args.readme_explanation)
    print("")
    print("```")
    if args.maximum_lines:
        old_stdout = sys.stdout
        sys.stdout = io.StringIO()
        return old_stdout
    return None


def stop_readme(args, old_stdout):
    """
    Print the postamble of a readme. If the output had a maximum # of lines,
    restore stdout and print those lines.
    """
    if args.maximum_lines:
        sio = sys.stdout
        sys.stdout = old_stdout
        ml = int(args.maximum_lines)
        for i, ln in enumerate(sio.getvalue().splitlines()):
            if i < ml:
                print(ln)
            elif i == ml:
                print(". . .")
            else:
                break
    print("```")
    print("")


class BooleanAction(argparse.Action):
    """
    Class that supports both --option and --no-option.
    https://thisdataguy.com/2017/07/03/no-options-with-argparse-and-python/

    To use:
    parser.add_argument("--option", "--no-option", action=BooleanAction, default=True/False)
    """

    def __init__(self, option_strings, dest, nargs=None, **kwargs):
        super().__init__(option_strings, dest, nargs=0, **kwargs)

    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, not option_string.startswith("--no"))


def parse_options(conf):
    """Set up all of the option parsing"""
    conf = {} if conf is None else conf

    parser = argparse.ArgumentParser(description=__doc__, epilog=EPILOG)
    grp_search = parser.add_argument_group("Search Options")

    grp_search_worlds = grp_search.add_mutually_exclusive_group()
    grp_search_worlds.add_argument("-W", "--worlds", help="Search the world standings.", action="store_true")
    grp_search_worlds.add_argument("-t", "--top", help="Search the world standings.", action="store_true")

    grp_search_state = grp_search.add_mutually_exclusive_group()
    grp_search_state.add_argument(
        "-S",
        "--state",
        "--province",
        help="State/Province to search. May be specified multiple times.",
        type=str,
        action="append",
    )
    grp_search_state.add_argument(
        "--all-states", "--all-provinces", help="Search all states and provinces.", action="store_true"
    )
    grp_search_state.add_argument("--all-us", help="Search all of the US.", action="store_true")
    grp_search_state.add_argument("--all-canada", help="Search all of Canada.", action="store_true")

    grp_search_district = grp_search.add_mutually_exclusive_group()
    grp_search_district.add_argument(
        "-d", "--district", help="District to search. May be specified multiple times.", type=str, action="append"
    )
    grp_search_district.add_argument("--all-districts", help="Search all districts.", action="store_true")

    # search options
    grp_search.add_argument("-s", "--search", help="String to search for in the standings.", type=str, default="")
    grp_search.add_argument(
        "-k",
        "--keep-division-if",
        help="Keep division if this string is found in the standings. May be specified multiple times.",
        type=str,
        action="append",
    )
    grp_search.add_argument(
        "-p",
        "--maximum-place",
        help="Only print places with a number <= than this. (e.g. 1 means 1st place) Default: all",
        type=int,
        default=99,
    )
    grp_search.add_argument(
        "-c",
        "--division-code",
        help="Only print this division. May be specified multiple times.",
        type=str,
        action="append",
    )
    grp_search.add_argument(
        "--competition",
        help=f"Only print this competition, one of {list(COMPETITIONS.values())}. May be specified multiple times.",
        type=str,
        action="append",
    )

    ################
    # output options
    ################
    grp_output = parser.add_argument_group("Output Options")
    grp_output.add_argument(
        "-b", "--by-person", help="Print the standings by name", action="store_true", default=conf.get("by-person")
    )
    grp_output.add_argument(
        "-B",
        "--by-person-with-divisions",
        help="Print the standings by name",
        action="store_true",
        default=conf.get("by-person-with-divisions"),
    )
    grp_output.add_argument(
        "-O",
        "--omit",
        help="Item to skip printing. May be specified multiple times.",
        type=str,
        action="append",
        default=conf.get("omit"),
    )
    grp_output.add_argument(
        "-m",
        "--minimize",
        help="Item to minimize when printing. May be specified multiple times.",
        type=str,
        action="append",
        default=conf.get("minimize"),
    )
    grp_search.add_argument(
        "-l",
        "--list-division-codes",
        help="List the division codes instead of printing standings",
        action="store_true",
        default=conf.get("list-division-codes"),
    )
    grp_search.add_argument("-J", "--output-json", help=argparse.SUPPRESS, action="store_true")
    grp_search.add_argument("-P", "--print", help=argparse.SUPPRESS, action="store_true")

    ################
    # connection control options
    ################
    grp_conn = parser.add_argument_group("Connection Control Options")
    grp_conn.add_argument(
        "--connection-count",
        help="Number of connection attempts per web page",
        type=int,
        default=conf.get("connection-count", 1),
    )
    grp_conn.add_argument(
        "--retry-interval",
        help="Seconds between connection attempts when retrying",
        type=int,
        default=conf.get("retry-interval", 30),
    )
    grp_conn.add_argument(
        "--request-interval",
        help="Seconds between successful connection attempts",
        type=int,
        default=conf.get("request-interval", 1),
    )

    ################
    # cache control options
    ################
    grp_cache = parser.add_argument_group("Cache Control Options")
    grp_cache.add_argument(
        "-C",
        "--cache-directory",
        help="Keep a cache of the web pages in this directory.",
        type=str,
        default=conf.get("cache-directory", get_cache_dir()),
    )
    grp_cache_inc = grp_cache.add_mutually_exclusive_group()
    grp_cache_inc.add_argument(
        "-I",
        "--ignore-existing-cache",
        help="Ignore any existing cache of the web pages. (Still create one though.)",
        action="store_true",
    )
    grp_cache_inc.add_argument(
        "--offline",
        "--no-offline",
        help="Run offline using the cache. (Implies -T/--ignore-cache-times)",
        action=BooleanAction,
        default=conf.get("offline", False),
    )
    grp_cache_time = grp_cache.add_mutually_exclusive_group()
    grp_cache_time.add_argument(
        "-T",
        "--ignore-cache",
        "--ignore-cache-times",
        help="Do not timeout any existing cache of the web pages.",
        action="store_true",
        default=conf.get("ignore-cache", False),
    )
    grp_cache_time.add_argument(
        "-w",
        "--use-web-standings-dates",
        help="Verify 'standings updated' date in the file against the web page.",
        action="store_true",
        default=conf.get("use-web-standings-dates", False),
    )
    grp_cache_time.add_argument(
        "--use-time-based-cache",
        help="Use a time-based 24-hour cache.",
        action="store_true",
        default=conf.get("use-time-based-cache", False),
    )
    grp_cache.add_argument(
        "-D", "--do-not-write-cache", help="Do not write a cache of the web pages.", action="store_true"
    )
    grp_cache.add_argument(
        "--clean-cache", help="Remove all of the files in the current cache of the web pages.", action="store_true"
    )

    grp_cache_zip = grp_cache.add_mutually_exclusive_group()
    grp_cache_zip.add_argument(
        "--gzip-cache",
        "--no-gzip-cache",
        help="Save cache files using gzip",
        action=BooleanAction,
        default=conf.get("gzip-cache", False),
    )
    grp_cache_zip.add_argument(
        "--bzip2-cache",
        "--no-bzip2-cache",
        help="Save cache files using bzip2",
        action=BooleanAction,
        default=conf.get("bzip2-cache", False),
    )

    ################
    # other options
    ################
    grp_other = parser.add_argument_group("Other Options")
    grp_other.add_argument(
        "-v",
        "--verbose",
        help="Verbose, print some debugging information. May be specified multiple times for higher verbosity levels.",
        action="count",
        default=conf.get("verbose", 0),
    )
    grp_other.add_argument(
        "--dots",
        "--no-dots",
        help="Print a dot, comma or semi-colon for each web page accessed.",
        action=BooleanAction,
        default=conf.get("dots"),
    )
    grp_other.add_argument("--extended-help", help="Show the preamble of the README", action="store_true")
    grp_other.add_argument("--update-cache", help="Update all cached files based.", action="store_true")

    ################
    # "invisible" options
    ################
    for a, arg, has_option in SUPPRESSED_ARGUMENTS:
        if has_option:
            grp_other.add_argument(a, arg, help=argparse.SUPPRESS, type=str)
        else:
            grp_other.add_argument(a, arg, help=argparse.SUPPRESS, action="store_true")
    return (parser, parser.parse_args())


def get_configuration():
    """
    Look for a configuration file and mix its values in
    with the command line.
    Look for the first of:
        dirname($0)/.atastandings.yaml
        ~/.atastandings.yaml
    """

    averbose = sum(key in ("-v", "--verbose") for key in sys.argv)

    yaml_name = "/.atastandings.ini"
    conf_args = {}
    for conf in [
        os.path.dirname(os.path.realpath(__file__)) + yaml_name,
        os.getenv("HOME", "/does-not-exist/") + yaml_name,
        os.getenv("HOMEPATH", "/does-not-exist/") + yaml_name,
    ]:
        if averbose:
            print(f"looking for {conf}", file=sys.stderr, flush=True)

        try:
            with open(conf) as fp:
                conf_args = yaml.safe_load(fp)
                return conf_args
        except yaml.YAMLError as e:
            print(f"Error parsing {conf}: {e}", file=sys.stderr)
        except FileNotFoundError:
            pass  # go to the next one

    return {}


def add_environment(conf):
    """
    Check the $ATASTANDINGS environment variable for configuration seetings.
    Use an encoding of yaml with ";" representing newlines, as in:

    dots: true; use-web-standings-dates: false
    """
    atastandings = os.environ.get("ATASTANDINGS")
    if atastandings is None:
        return

    try:
        conf2 = yaml.safe_load(re.sub("; *", "\n", atastandings))
    except Exception as e:
        sys.exit(f"Error parsing {atastandings}: {e}")

    for k, v in conf2.items():
        conf[k] = v


def find_duplicates(nm, arr):
    """Look for duplicates in the list"""
    s = set()
    for p in arr:
        if p in s:
            print(f"the value {p} is duplicated in {nm}")
        else:
            s.add(p)


def check_global_arrays():
    """Cross check some of the arrays looking for mistakes"""
    find_duplicates("CA_PROVINCES", CA_PROVINCES)
    find_duplicates("US_STATES", US_STATES)
    all_districts = [value for array in DISTRICTS.values() for value in array]
    find_duplicates("DISTRICTS", all_districts)
    find_duplicates("CA_PROVINCES+US_STATES", CA_PROVINCES + US_STATES)


def get_standings_date(text):
    """
    Search a web page for the text
    'Standings updated on mm/dd/yyyy'
    and return the date.
    """
    m = re.search("Standings updated on ([^<]*)<", text)
    return m.group(1) if m else None


def update_cache_worldstate(args, base, standing_type):
    """
    Search for matching standings files in the cache directory.
    For each matching standings files, update as needed.
    """
    print(f"update_cache for {standing_type}")

    # Force various options
    args.ignore_existing_cache = False
    args.offline = False

    g = f"{args.cache_directory}/atastandings.{base}*"
    found_updated = False

    for fname in glob.glob(g):
        bfname = os.path.basename(fname)
        url = decode_url(bfname)
        (_, updated) = get_url(args, url, standing_type)
        print("+" if updated else "-", end="", file=sys.stderr)
        if updated:
            found_updated = True
    print()
    return found_updated


def update_cache(args):
    """
    Search for standings files in the cache directory.
    Look first for world standings files, then for state standings files.
    """
    s = update_cache_worldstate(args, f"{STATE_SUFFIX}", STANDINGS_STATES)
    w = update_cache_worldstate(args, f"{WORLD_SUFFIX}", STANDINGS_WORLDS)
    return (s, w)


def expand_comma_lists(lst):
    """
    Given a list where some elements look like AB and others like CD,EF,...,
    create a new list AB,CD,EF,...
    """
    if lst is None:
        return lst
    ret = []
    for l in lst:
        for nl in l.split(","):
            ret.append(nl.strip())
    return ret


def check_numeric_option(parser, val, name, min_value=1):
    """Check the value make sure it is >= min_value."""
    if val < min_value:
        parser.error(f"{sys.argv[0]}: error: error {name} must be >= {min_value}, not '{val}'")


def usage(parser, msg):
    """
    Print a usage message along with an error message.
    """
    parser.print_usage(sys.stderr)
    barg0 = os.path.basename(sys.argv[0])
    print(f"{barg0}: error: {msg}", file=sys.stderr)
    sys.exit(2)


def main():
    """main function"""
    conf = get_configuration()
    add_environment(conf)
    (parser, args) = parse_options(conf)

    # check the data
    check_global_arrays()

    if args.internal_checks:
        print("Internal checks complete")
        sys.exit()

    if args.update_cache:
        (state_updated, world_updated) = update_cache(args)
        if state_updated:
            print("Cached state files were updated")
        if world_updated:
            print("Cached world files were updated")
        sys.exit(state_updated + 2 * world_updated)

    # check the value of --top option
    if args.top and args.list_division_codes:
        usage(parser, "--top and -l/--list-division-codes cannot be used together")

    # check the values of the --omit option
    args.omit = expand_comma_lists(args.omit)
    check_option(args.omit, "-O/--omit", OMIT_CHOICES)

    # check the values of the --minimize option
    args.minimize = expand_comma_lists(args.minimize)
    check_option(args.minimize, "-m/--minimize", MINIMIZE_CHOICES)

    # check the values of the --district option
    if args.all_districts:
        args.district = DISTRICTS.keys()
    if args.district:
        args.district = expand_comma_lists(args.district)
        # Re-capitalize the district names
        for i, district in enumerate(args.district):
            args.district[i] = "-".join([x.capitalize() for x in district.split("-")])
        check_option(args.district, "-d/--district", DISTRICTS.keys())

    # check the values of the --competition option
    args.competition = expand_comma_lists(args.competition)
    check_option(args.competition, "--competiton", COMPETITIONS.keys())

    # Check the values of the --state/--province, --all-states/--all-provinces, --all-us, --all-canada options.
    # Argparse already makes these options exclusive.
    # The web site allows for both lower and upper case for states. Upper case displays better.
    if args.all_states:
        args.state = US_STATES + CA_PROVINCES
    elif args.all_us:
        args.state = US_STATES
    elif args.all_canada:
        args.state = CA_PROVINCES
    upper_case(args.state)
    args.state = expand_comma_lists(args.state)
    check_option(args.state, "-S/--state", US_STATES + CA_PROVINCES)

    # Check the values of the connection settings.
    check_numeric_option(parser, args.connection_count, "--connection-count")
    check_numeric_option(parser, args.retry_interval, "--retry-interval")
    check_numeric_option(parser, args.retry_interval, "--request-interval", min_value=0)

    # Check the values of the cache settings. Default to --use-web-standings-dates.
    if not args.ignore_cache and not args.use_web_standings_dates and not args.use_time_based_cache:
        args.use_web_standings_dates = True

    # Check the values of the print settings
    if not args.output_json and not args.print:
        args.print = True

    if args.extended_help:
        # pylint: disable=protected-access
        print_readme_heading(parser._actions, False)

    if args.output:
        # pylint: disable=consider-using-with
        sys.stdout = open(args.output, "a")

    if args.print_readme_heading:
        # pylint: disable=protected-access
        print_readme_heading(parser._actions)

    if args.print_readme_trailer:
        print_readme_trailer()

    if args.generate_readme:
        old_stdout = start_readme(args)

    if args.clean_cache:
        clean_cache(args)

    if not args.worlds and not args.district and not args.state:
        args.worlds = True

    try:
        if args.worlds:
            print_worlds(args)

        if args.top:
            print_top(args)

        else:
            if args.district:
                print_districts(args, args.worlds)

            if args.state:
                print_states(args, args.worlds or args.district)

    except BrokenPipeError:
        pass

    if args.generate_readme:
        stop_readme(args, old_stdout)


if __name__ == "__main__":
    main()
