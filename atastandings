#!/usr/bin/env python3

""" Search the ATA World and State/Province standings """

# See the LICENSE file for the license to use and modify this program.

import argparse
import glob
import html
import io
import os
import random
import re
import sys
import time

import requests

EPILOG = "-W and -S can be used together, or separately. If neither -W nor -S are set, default to -W"
WORLDBASE = "https://atamartialarts.com/events/tournament-standings/worlds-standings/"
STATEBASE = "https://atamartialarts.com/events/tournament-standings/state-standings/"
NAME_SUFFIXES = ["jr.", "sr.", "i", "ii", "iii", "iv"]
NAME_PREFIXES = ["van", "san", "de", "da", "los", "st.", "saint"]


RANDOM_WORDS = []
USED_WORDS = []
RANDOM_NAME_MAP = {}


def get_next_random_word():
    """
    Return the next random word from RANDOM_WORDS.
    Push the word onto USED_WORDS.
    If none are left in RANDOM_WORDS, reassign RANDOM_WORDS and reshuffle.
    """
    global RANDOM_WORDS, USED_WORDS
    if not RANDOM_WORDS:
        RANDOM_WORDS = USED_WORDS
        USED_WORDS = []
        random.shuffle(RANDOM_WORDS)
    wd = RANDOM_WORDS.pop(0)
    USED_WORDS.append(wd)
    return wd


def get_random_word(nm):
    """
    Given a name, return a random name to use in its place.
    Do this by grabbing two random words at a time from the front of the list.
    """
    global RANDOM_NAME_MAP
    while True:
        repl_name = get_next_random_word().capitalize() + get_next_random_word()
        if repl_name not in RANDOM_NAME_MAP:
            RANDOM_NAME_MAP[nm] = repl_name
            return repl_name


def get_random_name(args, nm):
    """
    Given a name, and randomizing is on, return a random name to use in its place.
    """
    if not args.randomize_names:
        return nm

    global RANDOM_WORDS, USED_WORDS, NAME_SUFFIXES
    if not RANDOM_WORDS and not USED_WORDS:
        with open(args.randomize_names) as fp:
            for l in fp:
                RANDOM_WORDS.append(l.strip().lower())
        random.shuffle(RANDOM_WORDS)
        for nm in NAME_SUFFIXES:
            RANDOM_NAME_MAP[nm] = nm
        for nm in NAME_PREFIXES:
            RANDOM_NAME_MAP[nm] = nm

    newname = []
    for l in nm.lower().split():
        newname.append(get_random_word(l))
    return " ".join(newname)


def get_cache_dir():
    """Determine the directory where to store a cache of the web files"""
    for name in ["TEMP", "TMP", "TMPDIR", "TEMPDIR"]:
        dirname = os.environ.get(name)
        if dirname:
            return dirname
    return "/tmp"


def strip_html(l):
    """strip out all html <tags>"""
    l = re.sub("<[^>]*>", "", l)
    l = re.sub(r"\s+", " ", l)
    return l


def get_url(args, url):
    """
    Retrieve a URL. Exit with an error message if there is an error retrieving it.
    Return the body as an array of lines.

    Note that this uses a cache, so that each web page is visited exactly once.
    This speeds up running the program multiple times in a row.
    There are options to ignore, disable and clean the cache.
    Cache files older than 24 hours are automatically ignored.
    """

    urlname = re.sub("[^a-zA-Z0-9_]", "", url)
    cachename = f"{args.cache_directory}/atastandings.{urlname}"
    usefile = not args.ignore_existing_cache
    if usefile:
        try:
            if args.verbose:
                print(f"looking for {args.cache_directory}/atastandings.{urlname}")
            st = os.stat(cachename)
            if time.time() - st.st_mtime > 24 * 60 * 60:  # ignore files older than 24 hours
                os.unlink(cachename)
                if args.verbose:
                    print(f"{cachename} is too old -- ignored")

            with open(cachename) as fp:
                text = fp.read()
        except FileNotFoundError:
            usefile = False

    if not usefile:
        if args.verbose:
            print(f"getting url={url}")
        r = requests.get(url)
        if r.status_code >= 300:
            sys.exit(f"Accessing {url} returned the status code {r.status_code}")

        if args.verbose > 2:
            print(f"page={r.text}")
        if not args.do_not_write_cache:
            if args.verbose:
                print(f"writing to {cachename}")
            with open(f"{cachename}", "w") as fp:
                fp.write(r.text)
        text = r.text

    return text.splitlines()


def clean_cache(args):
    """Clear out all files in the cache directory named "atastandings." followed by anything."""
    for fname in glob.glob(f"{args.cache_directory}/atastandings.*"):
        if args.verbose:
            print(f"Cleaning {fname}")
        os.unlink(fname)


def trim_border(lines, border):
    """
    Trim all lines up through the first line that includes the string border.
    Then trim all lines after border occurs again.
    Also trim any lines after "Listed Tournaments"
    """
    nl = []
    saving = False
    for l in lines:
        if border in l:
            if saving:
                break
        elif "Listed Tournaments" in l:
            break
        if saving:
            nl.append(l)
        if border in l:
            saving = True
    return nl


def join_li_td_tr(lines):
    """Join any lines that end with </li>, </td> and </th> with the subsequent line"""
    for i in range(len(lines) - 1):
        l = lines[i].strip().replace(" ", "")
        if l.endswith("</li>") or l.endswith("</td>") or l.endswith("</th>"):
            lines[i + 1] = lines[i] + lines[i + 1]
            lines[i] = ""
    return lines


def fgrep(s, lines):
    """search for lines that have the given string and return that array"""
    newlines = []
    for l in lines:
        if s in l:
            newlines.append(l)
    return newlines


def get_code(l):
    """extract code=ABC from a line"""
    l = re.sub("^.*code=", "code=", l)
    l = re.sub('".*$', "", l)
    return l


def fix_html(s):
    """Look in a string and replace instances of &xyz; with the equivalent values"""
    return html.unescape(s)


def get_codes(args, url):
    """Retrieve a URL. Retrieve the list of codes as an array of [division-code, division-name]"""
    lines = fgrep("code=", join_li_td_tr(get_url(args, url)))
    nl = []
    for l in lines:
        nl.append([get_code(l), strip_html(l).replace("VIEW", "")])
    return nl


def print_lines(lines):
    """print the lines of an array"""
    for l in lines:
        print(l)


def get_info(args, code, region, url, border):
    """Get the standings from this url"""
    lines = get_url(args, url)
    lines = trim_border(lines, border)
    dispcode = code[0].split("=")[1]
    for i, val in enumerate(lines):
        if "text-primary" in val:
            lines[i] = f"DIVISION {dispcode} {val}"
        lines[i] = re.sub(" +", " ", lines[i])
        lines[i] = re.sub('style="[^"]*"', "", lines[i])
        lines[i] = re.sub('class="[^"]*"', "", lines[i])

    lines = join_li_td_tr(lines)

    nl = []
    for l in lines:
        l = l.replace("</td>", "").replace("</th>", "").replace("</li>", "")
        l = re.sub("<t[rd][^>]*>", " | ", l)
        l = re.sub(r"^\s+[|]\s+", " ", l)
        l = re.sub("<[^>]*>", "", l)  # eliminates ALL html tags
        l = (
            l.replace("The points below", "")
            .replace("Back to Map", "")
            .replace("reflect the following tournaments", "")
        )
        l = re.sub(r"\s+", " ", l)
        if l in ("", " "):
            continue
        nl.append(l)

    # Convert the division info to a structure
    info = []
    curinfo = None
    for l in nl:
        if l.startswith("DIVISION"):
            div_parts = l.strip().split()
            curinfo = {
                "code": div_parts[1],
                "division": " ".join(div_parts[2:]),
                "region": region,
                "other_header": [],
                "places": [],
            }
            info.append(curinfo)
        elif re.match(r"\s*[a-zA-Z]", l):
            if curinfo is not None:
                curinfo["other_header"].append(l)
        elif re.match(r"\s*[0-9]+ .*" + args.search, l, flags=re.IGNORECASE):
            if curinfo is not None:
                place_info = l.split("|")
                curinfo["places"].append(
                    {
                        "place": int(place_info[0]),
                        "name": fix_html(get_random_name(args, place_info[1].strip())),
                        "points": int(place_info[2].strip()),
                        "location": place_info[3].strip(),
                    }
                )
    return info


def trim_info(args, info):
    """
    Apply the --search and --maximum-place criteria against the info array.
    """
    for i in info:
        new_places = []
        for j in i["places"]:
            keep = True
            if j["place"] > args.maximum_place:
                keep = False
            if args.search:
                if args.search.lower() not in j["name"].lower() and args.search.lower() not in j["location"].lower():
                    keep = False
            if keep:
                new_places.append(j)
        i["places"] = new_places
    new_info = []
    for i in info:
        if i["places"]:
            new_info.append(i)
    return new_info


def info_by_name(info):
    """given a structure'd set of standings, print it by division"""
    # {
    #    sortable_name => { "name": str, "location": str,
    #              "divisions": [
    #                  { "region": str, "division": str, "code": str, "place": int, "points": int }, ...
    #              ]}
    name_info = {}
    for i in info:
        for j in i["places"]:
            sname = sortable_name(j["name"])
            if sname not in name_info:
                name_info[sname] = {"name": j["name"], "divisions": [], "location": j["location"]}
            name_info[sname]["divisions"].append(
                {
                    "region": i["region"],
                    "division": i["division"],
                    "code": i["code"],
                    "place": j["place"],
                    "points": j["points"],
                }
            )

    return name_info


def omitted(args, nm, s):
    """
    Check if nm is in the args.omit list.
    If not, print the string s without a line ending.
    If so, return an empty string.
    """
    return s if not args.omit or nm not in args.omit else ""  # if nm in args.omit else s


def print_omitted(args, nm, s):
    """
    Check if nm is in the args.omit list.
    If not, print the string s without a line ending.
    """
    print(omitted(args, nm, s), end="")


def sortable_name(nm):
    """
    Return a name as LAST, FIRST.
    Suffixes "jr.", "sr.", "i", "ii", "iii" and "iv" are considered part of the last name
    Prefixes "van", "san", "de", "da", "los" "st.", "saint" are considered part of the last name
    """
    nm_parts = nm.lower().split()
    end = len(nm_parts)
    if nm_parts[end - 1] in NAME_SUFFIXES:
        end -= 1
    while end > 2 and nm_parts[end - 2] in NAME_PREFIXES:
        end -= 1
    return " ".join(nm_parts[end - 1 :]) + ", " + " ".join(nm_parts[0 : end - 1])


def print_info_by_name(args, info):
    """given a structure'd set of standings, print it by name"""
    name_info = info_by_name(info)
    for name in sorted(name_info.keys()):
        val = name_info[name]
        print_omitted(args, "name", val["name"])
        print_omitted(args, "location", f' {val["location"]}')
        if args.by_person_with_divisions:
            for div in val["divisions"]:
                print(" |", end="")
                print_omitted(args, "region", f' {div["region"]}')
                print_omitted(args, "place", f' {div["place"]}')
                print_omitted(args, "code", f' {div["code"]}')
                print_omitted(args, "division", f' {div["division"]}')
                print_omitted(args, "points", f' {div["points"]}')
        print("")


def print_info_by_division(args, info):
    """given a structure'd set of standings, print it by division"""
    for i in info:
        print(f"DIVISION", end="")
        print_omitted(args, "region", f' {i["region"]}')
        print_omitted(args, "code", f' {i["code"]}')
        print_omitted(args, "division", f' {i["division"]}')
        print("")
        for j in i["other_header"]:
            print(j)
        for j in i["places"]:
            print_omitted(args, "place", f' {j["place"]}')
            print_omitted(args, "name", f' {j["name"]}')
            print_omitted(args, "points", f' {j["points"]}')
            print_omitted(args, "location", f' {j["location"]}')
        print("")


def print_info(args, info):
    """given a structure'd set of standings, print it appropriately"""
    if args.by_person or args.by_person_with_divisions:
        print_info_by_name(args, info)
    else:
        print_info_by_division(args, info)


def print_worlds(args):
    """print the worlds standings"""
    if args.division_code:
        codes = [[f"code={code}", ""] for code in args.division_code]
    else:
        codes = get_codes(args, WORLDBASE)

    if args.list_division_codes:
        print("WORLD STANDINGS DIVISIONS")
        for code in codes:
            print(f"{code[0].split('=')[1]}: {code[1]}")

    else:
        if args.search:
            print(f"WORLD STANDINGS, searching for {args.search}, maximum place of {args.maximum_place}")
        else:
            print(f"WORLD STANDINGS, maximum place of {args.maximum_place}")
        all_info = []
        for code in codes:
            info = get_info(args, code, "WORLDS", f"{WORLDBASE}?{code[0]}", "INFO")
            all_info += info
        all_info = trim_info(args, all_info)
        print_info(args, all_info)


def print_states(args):
    """print the state standings"""
    # The web site allows for both lower and upper case. Upper case displays better.
    for i in range(len(args.state)):
        args.state[i] = args.state[i].upper()

    for state in args.state:
        if args.worlds or state != args.state[0]:
            print("")

        # https://atamartialarts.com/Scripts/state-standing.bundle.js
        # Set the country code appropriately based on the state.
        # Experimentally, it looks like "country=$COUNTRY" is NOT required,
        # but we'll pass it in anyway.
        if state in ["AB", "BC", "MB", "NB", "NL", "NS", "NT", "NU", "ON", "PE", "QC", "SK", "YT"]:
            COUNTRY = "CA"
        else:
            COUNTRY = "US"

        if args.division_code:
            codes = [[f"code={code}", ""] for code in args.division_code]
        else:
            codes = get_codes(args, f"{STATEBASE}?country={COUNTRY}&state={state}")

        if args.list_division_codes:
            print(f"STATE STANDINGS DIVISIONS FOR {state}")
            for code in codes:
                print(f"{code[0].split('=')[1]}: {code[1]}")

        else:
            if args.search:
                print(
                    f"STATE STANDINGS FOR {state}, searching for {args.search}, maximum place of {args.maximum_place}"
                )
            else:
                print(f"STATE STANDINGS FOR {state}, maximum place of {args.maximum_place}")
            all_info = []
            for code in codes:
                info = get_info(args, code, state, f"{STATEBASE}?country={COUNTRY}&state={state}&{code[0]}", "CONTENT")
                all_info += info
            all_info = trim_info(args, all_info)
            print_info(args, all_info)


def check_omit(args):
    """check the values of the --omit option"""
    if args.omit:
        omit_choices = [
            "location",
            "region",
            "place",
            "code",
            "division",
            "points",
        ]
        for omit in args.omit:
            if omit not in omit_choices:
                sys.exit(
                    f"{sys.argv[0]}: error: argument -O/--omit: invalid choice: '{omit}' (choose from "
                    f"{omit_choices})"
                )


def main():
    """main function"""
    parser = argparse.ArgumentParser(description=__doc__, epilog=EPILOG)
    grp_search = parser.add_argument_group("Search Options")
    grp_search.add_argument("-W", "--worlds", help="Search the world standings", action="store_true")
    grp_search.add_argument(
        "-S", "--state", help="State to search. May be specified multiple times.", type=str, action="append"
    )
    grp_search.add_argument("-s", "--search", help="Pattern to search for in the standings", type=str, default="")
    grp_search.add_argument(
        "-p",
        "--maximum-place",
        help="Only print places with a number <= than this. (e.g. 1 means 1st place) Default: all",
        type=int,
        default=99,
    )
    grp_search.add_argument(
        "-c",
        "--division-code",
        help="Only print this division. May be specified multiple times.",
        type=str,
        action="append",
    )

    grp_output = parser.add_argument_group("Output Options")
    grp_output.add_argument(
        "-b",
        "--by-person",
        help="Print the standings by name",
        action="store_true",
    )
    grp_output.add_argument(
        "-B",
        "--by-person-with-divisions",
        help="Print the standings by name",
        action="store_true",
    )
    grp_output.add_argument(
        "-O", "--omit", help="Item to skip printing. May be specified multiple times.", type=str, action="append"
    )
    grp_search.add_argument(
        "-l", "--list-division-codes", help="List the division codes instead of printing standings", action="store_true"
    )

    grp_cache = parser.add_argument_group("Cache Control Options")
    grp_cache.add_argument(
        "-C",
        "--cache-directory",
        help="Keep a cache of the web pages in this directory.",
        type=str,
        default=get_cache_dir(),
    )
    grp_cache.add_argument(
        "-I",
        "--ignore-existing-cache",
        help="Ignore any existing cache of the web pages. (Still create one though.)",
        action="store_true",
    )
    grp_cache.add_argument(
        "-D", "--do-not-write-cache", help="Do not write a cache of the web pages.", action="store_true"
    )
    grp_cache.add_argument(
        "--clean-cache", help="Remove all of the files in the current cache of the web pages.", action="store_true"
    )

    grp_other = parser.add_argument_group("Other Options")
    grp_other.add_argument(
        "-v",
        "--verbose",
        help="Verbose, print some debugging information. May be specified multiple times for higher verbosity levels.",
        action="count",
        default=0,
    )
    suppressed_arguments = [("-R", "--randomize-names"), ("-G", "--generate-readme"), ("-M", "--maximum-lines")]
    for a, arg in suppressed_arguments:
        grp_other.add_argument(a, arg, help=argparse.SUPPRESS, type=str)
    args = parser.parse_args()

    check_omit(args)
    if args.generate_readme:
        print(f"## `{args.generate_readme}`")
        print(f"`{os.path.basename(sys.argv[0])}", end="")
        sa1 = [item for sa in suppressed_arguments for item in sa]
        for arg in sys.argv[1:]:
            if arg not in sa1:
                print(f" {arg}", end="")
        print("`")
        print("")
        print("")
        print("``` shell")
        if args.maximum_lines:
            old_stdout = sys.stdout
            sys.stdout = io.StringIO()

    if args.clean_cache:
        clean_cache(args)

    if not args.worlds and not args.state:
        args.worlds = True

    try:
        if args.worlds:
            print_worlds(args)

        if args.state:
            print_states(args)
    except BrokenPipeError:
        pass

    if args.generate_readme:
        if args.maximum_lines:
            sio = sys.stdout
            sys.stdout = old_stdout
            ml = int(args.maximum_lines)
            for i, ln in enumerate(sio.getvalue().splitlines()):
                if i < ml:
                    print(ln)
                elif i == ml:
                    print(". . .")
                else:
                    break
        print("```")


if __name__ == "__main__":
    main()
